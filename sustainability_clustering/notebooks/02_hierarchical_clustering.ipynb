# =============================================================================
# MODULO 5: HIERARCHICAL CLUSTERING AVANZATO
# Ward Linkage + Dendrogramma + Confronto con risultati SAS + Bootstrap Stability
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import AgglomerativeClustering
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, adjusted_rand_score, calinski_harabasz_score
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster
from scipy.spatial.distance import pdist
from scipy.stats import f_oneway
import warnings
warnings.filterwarnings('ignore')

print("=== MODULO 5: HIERARCHICAL CLUSTERING AVANZATO ===")

# =============================================================================
# STEP 1: CARICAMENTO DATI (usando dataset processato SAS)
# =============================================================================

print("\n=== STEP 1: Caricamento dataset processato SAS ===")

# Usa il dataset finale SAS (meglio processato)
df = pd.read_excel('dataset_module4_python.xlsx', sheet_name='Dataset_Module4')

# Variabili clustering (stesse usate nei moduli SAS base)
clustering_vars = [
    'eta', 'genere_donna', 'titolo_magistrale', 'occup_studente', 
    'geo_isole', 'reddito_medio_alto', 
    'lik5_q15', 'lik5_q17', 'lik5_q27',
    'trasporto_sostenibile', 'ostacolo_costi', 'resp_governi', 'partec_attiva',
    'lik7_q8', 'lik7_q13', 'lik7_q19', 'lik7_q20', 'lik7_q21', 'lik7_q23'
]

# Estrai matrice clustering
X = df[clustering_vars].copy()
print(f"Dataset: {X.shape[0]} osservazioni, {X.shape[1]} variabili")
print(f"Missing values: {X.isnull().sum().sum()}")

# Standardizzazione (cruciale per clustering gerarchico)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("Dati standardizzati per clustering gerarchico")

# =============================================================================
# STEP 2: CALCOLO LINKAGE MATRIX E DENDROGRAMMA
# =============================================================================

print("\n=== STEP 2: Calcolo linkage matrix Ward ===")

# Calcola linkage matrix con metodo Ward (minimizza varianza intra-cluster)
print("Calcolo linkage Ward...")
linkage_matrix = linkage(X_scaled, method='ward', metric='euclidean')

print(f"Linkage matrix: {linkage_matrix.shape}")
print(f"Distanza massima fusione: {linkage_matrix[:, 2].max():.2f}")

# =============================================================================
# STEP 3: DENDROGRAMMA COMPLETO E ANALISI CUT-OFF
# =============================================================================

print("\n=== STEP 3: Generazione dendrogrammi ===")

# Dendrogramma completo
plt.figure(figsize=(20, 10))
dendr = dendrogram(linkage_matrix, 
                   labels=df['id'].astype(str).values,
                   leaf_rotation=90,
                   leaf_font_size=6,
                   color_threshold=0.7*linkage_matrix[:, 2].max())
plt.title('Dendrogramma Completo - Ward Linkage\nDataset Sostenibilità (151 osservazioni)', fontsize=16)
plt.xlabel('Osservazioni', fontsize=12)
plt.ylabel('Distanza Ward', fontsize=12)
plt.axhline(y=0.7*linkage_matrix[:, 2].max(), color='red', linestyle='--', linewidth=2,
            label='Soglia Cut-off Suggerita')
plt.legend()
plt.tight_layout()
plt.savefig('modulo5_dendrogramma_completo.png', dpi=300, bbox_inches='tight')
plt.show()

# Dendrogramma troncato (più leggibile)
plt.figure(figsize=(15, 8))
dendr_trunc = dendrogram(linkage_matrix, 
                        truncate_mode='lastp',
                        p=15,  # Mostra ultimi 15 merge
                        show_leaf_counts=True,
                        color_threshold=0.7*linkage_matrix[:, 2].max())
plt.title('Dendrogramma Troncato - Ultimi 15 Merge\nFocus su Struttura Clustering', fontsize=14)
plt.xlabel('Cluster (dimensioni tra parentesi)', fontsize=12)
plt.ylabel('Distanza Ward', fontsize=12)
plt.axhline(y=0.7*linkage_matrix[:, 2].max(), color='red', linestyle='--', linewidth=2)
plt.tight_layout()
plt.savefig('modulo5_dendrogramma_troncato.png', dpi=300, bbox_inches='tight')
plt.show()

print("Dendrogrammi generati e salvati")

# =============================================================================
# STEP 4: DETERMINAZIONE K OTTIMALE CON METRICHE MULTIPLE
# =============================================================================

print("\n=== STEP 4: Determinazione K ottimale per clustering gerarchico ===")

# Range K da testare
k_range = range(2, 8)

# Storage risultati
hier_results = {
    'k': [],
    'silhouette': [],
    'calinski_harabasz': [],
    'within_cluster_sum': [],
    'between_cluster_sum': []
}

print("Testing diversi valori di K...")

for k in k_range:
    print(f"  K={k}...", end=" ")
    
    # Clustering gerarchico
    hier_clusterer = AgglomerativeClustering(
        n_clusters=k,
        linkage='ward',
        metric='euclidean'
    )
    
    cluster_labels = hier_clusterer.fit_predict(X_scaled)
    
    # Verifica che abbiamo effettivamente k cluster
    n_clusters_found = len(np.unique(cluster_labels))
    
    if n_clusters_found == k:
        # Silhouette Score
        sil_score = silhouette_score(X_scaled, cluster_labels)
        
        # Calinski-Harabasz Index
        ch_score = calinski_harabasz_score(X_scaled, cluster_labels)
        
        # Within/Between cluster sum of squares
        cluster_centers = np.array([X_scaled[cluster_labels == i].mean(axis=0) 
                                   for i in range(k)])
        
        # Within-cluster sum of squares
        wcss = 0
        for i in range(k):
            cluster_data = X_scaled[cluster_labels == i]
            if len(cluster_data) > 0:
                wcss += np.sum((cluster_data - cluster_centers[i]) ** 2)
        
        # Between-cluster sum of squares  
        overall_center = X_scaled.mean(axis=0)
        bcss = 0
        for i in range(k):
            n_points = np.sum(cluster_labels == i)
            if n_points > 0:
                bcss += n_points * np.sum((cluster_centers[i] - overall_center) ** 2)
        
        # Store risultati
        hier_results['k'].append(k)
        hier_results['silhouette'].append(sil_score)
        hier_results['calinski_harabasz'].append(ch_score)
        hier_results['within_cluster_sum'].append(wcss)
        hier_results['between_cluster_sum'].append(bcss)
        
        print(f"Sil={sil_score:.3f}, CH={ch_score:.1f}")
        
    else:
        print(f"Solo {n_clusters_found}/{k} cluster effettivi")

# Trova K ottimali per ogni metrica
optimal_k_sil = hier_results['k'][np.argmax(hier_results['silhouette'])]
optimal_k_ch = hier_results['k'][np.argmax(hier_results['calinski_harabasz'])]

# Elbow method per WCSS
wcss_diffs = np.diff(hier_results['within_cluster_sum'])
wcss_diffs2 = np.diff(wcss_diffs)
if len(wcss_diffs2) > 0:
    optimal_k_elbow = hier_results['k'][np.argmax(wcss_diffs2) + 2]  # +2 per offset
else:
    optimal_k_elbow = 3

print(f"\nK ottimale Silhouette: {optimal_k_sil}")
print(f"K ottimale Calinski-Harabasz: {optimal_k_ch}")
print(f"K ottimale Elbow: {optimal_k_elbow}")

# Scelta K finale (consensus o default ai moduli SAS)
k_candidates = [optimal_k_sil, optimal_k_ch, optimal_k_elbow]
optimal_k_hier = max(set(k_candidates), key=k_candidates.count)  # Moda
if optimal_k_hier < 2:
    optimal_k_hier = 3  # Default ragionevole

print(f"K finale scelto: {optimal_k_hier}")

# =============================================================================
# STEP 5: VISUALIZZAZIONE CRITERI SELEZIONE K
# =============================================================================

print("\n=== STEP 5: Visualizzazione criteri selezione K ===")

fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

# Silhouette Score
ax1.plot(hier_results['k'], hier_results['silhouette'], 'bo-', linewidth=2, markersize=8)
ax1.axvline(optimal_k_sil, color='red', linestyle='--', alpha=0.7)
ax1.set_xlabel('Numero Cluster')
ax1.set_ylabel('Silhouette Score')
ax1.set_title(f'Silhouette Score vs K\n(Ottimale: K={optimal_k_sil})')
ax1.grid(True, alpha=0.3)

# Calinski-Harabasz Index
ax2.plot(hier_results['k'], hier_results['calinski_harabasz'], 'go-', linewidth=2, markersize=8)
ax2.axvline(optimal_k_ch, color='red', linestyle='--', alpha=0.7)
ax2.set_xlabel('Numero Cluster')
ax2.set_ylabel('Calinski-Harabasz Index')
ax2.set_title(f'Calinski-Harabasz Index vs K\n(Ottimale: K={optimal_k_ch})')
ax2.grid(True, alpha=0.3)

# Within-Cluster Sum of Squares (Elbow)
ax3.plot(hier_results['k'], hier_results['within_cluster_sum'], 'mo-', linewidth=2, markersize=8)
ax3.axvline(optimal_k_elbow, color='red', linestyle='--', alpha=0.7)
ax3.set_xlabel('Numero Cluster')
ax3.set_ylabel('Within-Cluster Sum of Squares')
ax3.set_title(f'Elbow Method\n(Ottimale: K={optimal_k_elbow})')
ax3.grid(True, alpha=0.3)

# Ratio Between/Within Sum of Squares
ratio_scores = np.array(hier_results['between_cluster_sum']) / np.array(hier_results['within_cluster_sum'])
ax4.plot(hier_results['k'], ratio_scores, 'co-', linewidth=2, markersize=8)
ax4.axvline(optimal_k_hier, color='red', linestyle='--', alpha=0.7)
ax4.set_xlabel('Numero Cluster')
ax4.set_ylabel('Between/Within SS Ratio')
ax4.set_title(f'Separazione Cluster\n(K finale: {optimal_k_hier})')
ax4.grid(True, alpha=0.3)

plt.suptitle('Selezione K Ottimale - Clustering Gerarchico Ward', fontsize=16)
plt.tight_layout()
plt.savefig('modulo5_optimal_k_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# STEP 6: FIT MODELLO FINALE E CONFRONTO CON MODULI SAS
# =============================================================================

print(f"\n=== STEP 6: Clustering gerarchico finale con K={optimal_k_hier} ===")

# Clustering gerarchico finale
hier_final = AgglomerativeClustering(
    n_clusters=optimal_k_hier,
    linkage='ward',
    metric='euclidean'
)

hier_labels = hier_final.fit_predict(X_scaled)

# Aggiungi al dataframe
df['hier_cluster'] = hier_labels

# Statistiche distribuzione
print("Distribuzione cluster gerarchici:")
hier_counts = pd.Series(hier_labels).value_counts().sort_index()
for i, count in hier_counts.items():
    percentage = count / len(df) * 100
    print(f"Cluster {i}: {count} osservazioni ({percentage:.1f}%)")

# Calcola metriche qualità
hier_silhouette = silhouette_score(X_scaled, hier_labels)
hier_ch = calinski_harabasz_score(X_scaled, hier_labels)

print(f"\nQualità clustering gerarchico K={optimal_k_hier}:")
print(f"Silhouette Score: {hier_silhouette:.3f}")
print(f"Calinski-Harabasz Index: {hier_ch:.1f}")

# Confronto con risultati moduli SAS (se disponibili)
print(f"\n=== STEP 6b: Confronto con risultati moduli SAS ===")

# Prova a confrontare con risultati precedenti
try:
    # Cerca risultati precedenti
    sas_results_files = ['modulo4_robust_results.csv', 'modulo4_intelligent_results.csv']
    sas_comparison_done = False
    
    for filename in sas_results_files:
        try:
            sas_results = pd.read_csv(filename)
            if len(sas_results) == len(df) and 'cluster' in sas_results.columns:
                # Confronta clustering
                ari_sas_hier = adjusted_rand_score(hier_labels, sas_results['cluster'])
                print(f"ARI Hierarchical vs SAS ({filename}): {ari_sas_hier:.3f}")
                
                # Tabella crosstab
                print(f"\nTabella confronto Hierarchical vs SAS:")
                crosstab = pd.crosstab(hier_labels, sas_results['cluster'], 
                                     margins=True, margins_name="Totale")
                print(crosstab)
                
                sas_comparison_done = True
                break
                
        except FileNotFoundError:
            continue
            
    if not sas_comparison_done:
        print("Risultati SAS non disponibili per confronto diretto")
        print("Confronto sarà fatto nell'interpretazione business")
        
except Exception as e:
    print(f"Errore nel confronto con SAS: {e}")

# =============================================================================
# STEP 7: PROFILING DETTAGLIATO CLUSTER GERARCHICI
# =============================================================================

print(f"\n=== STEP 7: Profiling {optimal_k_hier} cluster gerarchici ===")

# Profili cluster gerarchici
hier_profiles = df.groupby('hier_cluster')[clustering_vars].mean()
print("\nProfili cluster gerarchici (prime 10 variabili):")
print(hier_profiles.iloc[:, :10].round(3))

# Salva profili completi
hier_profiles.to_csv('modulo5_hier_cluster_profiles.csv')

# Test ANOVA per significatività
print(f"\n=== Test ANOVA differenze tra cluster gerarchici ===")
hier_significant_vars = []

for var in clustering_vars:
    groups = [df[df['hier_cluster'] == i][var].values for i in range(optimal_k_hier)]
    
    try:
        f_stat, p_value = f_oneway(*groups)
        
        if p_value < 0.05:
            hier_significant_vars.append(var)
            sig_level = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*"
            print(f"{var}: F={f_stat:.2f}, p={p_value:.4f} {sig_level}")
            
    except Exception as e:
        print(f"{var}: Errore ANOVA - {e}")

print(f"\nVariabili significative clustering gerarchico: {len(hier_significant_vars)}/{len(clustering_vars)}")

# =============================================================================
# STEP 8: ANALISI STABILITÀ BOOTSTRAP
# =============================================================================

print(f"\n=== STEP 8: Analisi stabilità bootstrap ===")

# Bootstrap stability analysis
n_bootstrap = 30  # Ridotto per velocità
bootstrap_ari = []

print(f"Bootstrap analysis con {n_bootstrap} campioni...")

np.random.seed(42)
for i in range(n_bootstrap):
    if (i + 1) % 10 == 0:
        print(f"  Completato {i+1}/{n_bootstrap}")
        
    # Campionamento bootstrap
    bootstrap_indices = np.random.choice(len(X_scaled), len(X_scaled), replace=True)
    X_bootstrap = X_scaled[bootstrap_indices]
    
    try:
        # Clustering su campione bootstrap
        hier_bootstrap = AgglomerativeClustering(n_clusters=optimal_k_hier, linkage='ward')
        bootstrap_labels = hier_bootstrap.fit_predict(X_bootstrap)
        
        # Confronta con clustering originale sugli stessi indici
        original_labels_subset = hier_labels[bootstrap_indices]
        
        # ARI tra bootstrap e originale
        ari = adjusted_rand_score(bootstrap_labels, original_labels_subset)
        bootstrap_ari.append(ari)
        
    except Exception:
        # Se il bootstrap fallisce, aggiungi un valore basso
        bootstrap_ari.append(0.1)

# Statistiche stabilità
stability_mean = np.mean(bootstrap_ari)
stability_std = np.std(bootstrap_ari)
stability_min = np.min(bootstrap_ari)
stability_q25 = np.percentile(bootstrap_ari, 25)
stability_q75 = np.percentile(bootstrap_ari, 75)

print(f"\nStatistiche stabilità clustering gerarchico:")
print(f"ARI medio bootstrap: {stability_mean:.3f} ± {stability_std:.3f}")
print(f"ARI mediano: {np.median(bootstrap_ari):.3f}")
print(f"ARI min-max: {stability_min:.3f} - {np.max(bootstrap_ari):.3f}")
print(f"IQR: {stability_q25:.3f} - {stability_q75:.3f}")

stability_quality = "Alta" if stability_mean > 0.7 else "Media" if stability_mean > 0.5 else "Bassa"
print(f"Valutazione stabilità: {stability_quality}")

# Visualizza distribuzione stabilità
plt.figure(figsize=(10, 6))
plt.hist(bootstrap_ari, bins=15, alpha=0.7, edgecolor='black', color='skyblue')
plt.axvline(stability_mean, color='red', linestyle='-', linewidth=2, 
            label=f'Media: {stability_mean:.3f}')
plt.axvline(np.median(bootstrap_ari), color='orange', linestyle='--', linewidth=2,
            label=f'Mediana: {np.median(bootstrap_ari):.3f}')
plt.xlabel('Adjusted Rand Index')
plt.ylabel('Frequenza')
plt.title(f'Distribuzione Stabilità Bootstrap\nClustering Gerarchico (K={optimal_k_hier})')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.savefig('modulo5_stability_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# =============================================================================
# STEP 9: INTERPRETAZIONE BUSINESS DEI CLUSTER
# =============================================================================

print(f"\n=== STEP 9: Interpretazione business cluster gerarchici ===")

cluster_interpretations = {}

for cluster_id in range(optimal_k_hier):
    cluster_data = df[df['hier_cluster'] == cluster_id]
    n_obs = len(cluster_data)
    
    print(f"\n--- CLUSTER GERARCHICO {cluster_id} ({n_obs} osservazioni, {n_obs/len(df)*100:.1f}%) ---")
    
    # Caratteristiche demografiche principali
    eta_mean = cluster_data['eta'].mean()
    genere_perc = cluster_data['genere_donna'].mean() * 100
    magistrale_perc = cluster_data['titolo_magistrale'].mean() * 100
    studenti_perc = cluster_data['occup_studente'].mean() * 100
    isole_perc = cluster_data['geo_isole'].mean() * 100
    
    print(f"Demografia: Età norm={eta_mean:.2f}, Donne={genere_perc:.0f}%, Magistrale={magistrale_perc:.0f}%")
    print(f"          Studenti={studenti_perc:.0f}%, Isole={isole_perc:.0f}%")
    
    # Comportamenti sostenibilità chiave
    trasporto_sost_perc = cluster_data['trasporto_sostenibile'].mean() * 100
    ostacoli_costi_perc = cluster_data['ostacolo_costi'].mean() * 100
    partecip_attiva_perc = cluster_data['partec_attiva'].mean() * 100
    
    print(f"Sostenibilità: Trasporto sostenibile={trasporto_sost_perc:.0f}%")
    print(f"              Ostacolo costi={ostacoli_costi_perc:.0f}%, Partecipazione={partecip_attiva_perc:.0f}%")
    
    # Sample atteggiamenti Likert
    likert_sample = ['lik7_q8', 'lik7_q13', 'lik7_q19']
    likert_means = [cluster_data[var].mean() for var in likert_sample]
    print(f"Atteggiamenti (1-7): Q8={likert_means[0]:.1f}, Q13={likert_means[1]:.1f}, Q19={likert_means[2]:.1f}")
    
    # Etichetta interpretativa
    if studenti_perc > 80:
        label = f"Studenti Sostenibili {cluster_id}"
    elif isole_perc > 50:
        label = f"Comunità Insulari {cluster_id}"
    elif trasporto_sost_perc > 50:
        label = f"Eco-Attivisti {cluster_id}"
    elif genere_perc > 70:
        label = f"Donne Impegnate {cluster_id}"
    elif ostacoli_costi_perc > 70:
        label = f"Limitati da Costi {cluster_id}"
    else:
        label = f"Gruppo Misto {cluster_id}"
    
    cluster_interpretations[cluster_id] = label
    print(f"Etichetta: '{label}'")

print("\n=== Continua con STEP 10: Visualizzazioni finali ===")
