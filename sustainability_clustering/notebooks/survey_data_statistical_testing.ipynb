# =============================================================================
# MODULO TEST ROBUSTEZZA SPECIFICA SURVEY DATA
# 1. Sensitivity Analysis Demografica
# 2. Item Response Theory (IRT) 
# 3. Measurement Invariance
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.model_selection import GroupKFold
from scipy import stats
from scipy.stats import chi2_contingency, kruskal
from factor_analyzer import FactorAnalyzer
from factor_analyzer.factor_analyzer import calculate_kmo
import warnings
warnings.filterwarnings('ignore')

print("=== MODULO TEST ROBUSTEZZA SPECIFICA SURVEY DATA ===")

# =============================================================================
# STEP 1: CARICAMENTO E PREPARAZIONE DATI
# =============================================================================

print("\n=== STEP 1: Preparazione per test robustezza ===")

# Carica dataset originale per accesso alle variabili demografiche raw
df_original = pd.read_excel('Questionario Sostenibilità 1 1.xlsx', 
                           sheet_name='Questionario Sostenibilità')

# Preprocessing ottimale (da analisi precedenti)
def prepare_clustering_data():
    df_encoded = df_original.copy()
    
    # Demografia encoding
    df_encoded['eta_norm'] = (df_encoded['q1'] - 18) / (70 - 18)
    df_encoded['genere_donna'] = (df_encoded['q2'] == 'Donna').astype(int)
    df_encoded['titolo_magistrale'] = (df_encoded['q3'] == 'Laurea Magistrale').astype(int)
    df_encoded['titolo_postlaurea'] = (df_encoded['q3'] == 'Formazione Post Laurea (Master/Dottorato)').astype(int)
    df_encoded['occup_studente'] = (df_encoded['q4'] == 'Studente/ Studentessa').astype(int)
    df_encoded['occup_privato'] = (df_encoded['q4'] == 'Lavoro dipendente privato').astype(int)
    df_encoded['geo_nord'] = df_encoded['q5'].isin(['Nord Est', 'Nord Ovest']).astype(int)
    df_encoded['geo_centro'] = (df_encoded['q5'] == 'Centro').astype(int)
    df_encoded['reddito_alto'] = df_encoded['q6'].isin(['30001 - 50000', 'Più di 50000']).astype(int)
    df_encoded['reddito_basso'] = (df_encoded['q6'] == 'Meno di 15000').astype(int)
    
    clustering_vars = ['eta_norm', 'genere_donna', 'titolo_magistrale', 'titolo_postlaurea', 
                      'occup_studente', 'occup_privato', 'geo_nord', 'geo_centro', 
                      'reddito_alto', 'reddito_basso']
    
    return df_encoded, clustering_vars

df_processed, clustering_vars = prepare_clustering_data()

# Aggiungi variabili demografiche raw per grouping
df_processed['eta_raw'] = df_original['q1']
df_processed['genere_raw'] = df_original['q2']
df_processed['occupazione_raw'] = df_original['q4']
df_processed['titolo_raw'] = df_original['q3']

# Dataset clustering standardizzato
scaler = StandardScaler()
X_clustering = scaler.fit_transform(df_processed[clustering_vars].fillna(0))

# Clustering di riferimento (K=3 ottimale dalle analisi precedenti)
kmeans_ref = KMeans(n_clusters=3, random_state=42, n_init=10)
reference_labels = kmeans_ref.fit_predict(X_clustering)

print(f"Dataset preparato: {X_clustering.shape}")
print(f"Distribuzione cluster riferimento: {np.bincount(reference_labels)}")

# =============================================================================
# STEP 2: SENSITIVITY ANALYSIS DEMOGRAFICA
# =============================================================================

print("\n=== STEP 2: Sensitivity Analysis Demografica ===")

# Definisci sottogruppi demografici da testare
demographic_subgroups = {
    'Solo_Studenti': df_processed['occup_studente'] == 1,
    'Solo_Non_Studenti': df_processed['occup_studente'] == 0,
    'Solo_Donne': df_processed['genere_donna'] == 1,
    'Solo_Uomini': df_processed['genere_donna'] == 0,
    'Solo_Giovani': df_processed['eta_raw'] <= 30,
    'Solo_Over30': df_processed['eta_raw'] > 30,
    'Solo_Laureati': (df_processed['titolo_magistrale'] == 1) | (df_processed['titolo_postlaurea'] == 1),
    'Solo_Non_Laureati': (df_processed['titolo_magistrale'] == 0) & (df_processed['titolo_postlaurea'] == 0),
    'Solo_Reddito_Alto': df_processed['reddito_alto'] == 1,
    'Solo_Reddito_Basso': df_processed['reddito_basso'] == 1
}

sensitivity_results = []

print("Testing robustezza clustering per sottogruppi demografici:")

for subgroup_name, mask in demographic_subgroups.items():
    n_subgroup = np.sum(mask)
    
    if n_subgroup < 30:  # Minimo per clustering affidabile
        print(f"  {subgroup_name}: Skip - troppo pochi casi ({n_subgroup})")
        continue
        
    print(f"  {subgroup_name}: n={n_subgroup}...", end=" ")
    
    try:
        # Dati sottogruppo
        X_subgroup = X_clustering[mask]
        reference_subgroup = reference_labels[mask]
        
        # Clustering su sottogruppo
        kmeans_sub = KMeans(n_clusters=3, random_state=42, n_init=10)
        subgroup_labels = kmeans_sub.fit_predict(X_subgroup)
        
        # Metriche qualità
        n_clusters_found = len(np.unique(subgroup_labels))
        
        if n_clusters_found > 1:
            subgroup_silhouette = silhouette_score(X_subgroup, subgroup_labels)
            
            # ARI con clustering di riferimento (stesso sottogruppo)
            ari_with_reference = adjusted_rand_score(reference_subgroup, subgroup_labels)
            
        else:
            subgroup_silhouette = 0.0
            ari_with_reference = 0.0
        
        sensitivity_results.append({
            'Subgroup': subgroup_name,
            'N_Cases': n_subgroup,
            'N_Clusters_Found': n_clusters_found,
            'Silhouette': subgroup_silhouette,
            'ARI_vs_Reference': ari_with_reference,
            'Valid': n_clusters_found == 3
        })
        
        print(f"Sil={subgroup_silhouette:.3f}, ARI={ari_with_reference:.3f}")
        
    except Exception as e:
        print(f"Errore - {str(e)[:30]}")
        sensitivity_results.append({
            'Subgroup': subgroup_name,
            'N_Cases': n_subgroup,
            'N_Clusters_Found': 0,
            'Silhouette': 0.0,
            'ARI_vs_Reference': 0.0,
            'Valid': False
        })

sensitivity_df = pd.DataFrame(sensitivity_results)

# Analisi risultati sensitivity
print(f"\nRisultati Sensitivity Analysis:")
valid_results = sensitivity_df[sensitivity_df['Valid'] == True]

if len(valid_results) > 0:
    print(f"Sottogruppi con clustering valido: {len(valid_results)}/{len(sensitivity_df)}")
    print(f"ARI medio con riferimento: {valid_results['ARI_vs_Reference'].mean():.3f} ± {valid_results['ARI_vs_Reference'].std():.3f}")
    print(f"Silhouette medio sottogruppi: {valid_results['Silhouette'].mean():.3f}")
    
    # Identifica sottogruppi più/meno stabili
    most_stable = valid_results.loc[valid_results['ARI_vs_Reference'].idxmax()]
    least_stable = valid_results.loc[valid_results['ARI_vs_Reference'].idxmin()]
    
    print(f"Più stabile: {most_stable['Subgroup']} (ARI={most_stable['ARI_vs_Reference']:.3f})")
    print(f"Meno stabile: {least_stable['Subgroup']} (ARI={least_stable['ARI_vs_Reference']:.3f})")
else:
    print("Nessun sottogruppo ha prodotto clustering valido")

# =============================================================================
# STEP 3: ITEM RESPONSE THEORY (IRT) ANALYSIS
# =============================================================================

print("\n=== STEP 3: Item Response Theory (IRT) Analysis ===")

# Identifica scale Likert per IRT
likert_vars = ['q7', 'q8', 'q9', 'q10', 'q11', 'q12', 'q13', 'q14', 
               'q16', 'q18', 'q19', 'q20', 'q21', 'q23', 'q24', 'q29']

# Filtra variabili esistenti
existing_likert = [var for var in likert_vars if var in df_original.columns]
print(f"Variabili Likert per IRT: {len(existing_likert)}")

# Dataset Likert pulito
df_likert = df_original[existing_likert].dropna()
print(f"Casi completi per IRT: {len(df_likert)}")

if len(df_likert) >= 50:  # Minimo per IRT
    # Test fattorabilità
    kmo_all, kmo_model = calculate_kmo(df_likert)
    print(f"KMO per fattorabilità: {kmo_model:.3f}")
    
    if kmo_model > 0.6:  # Accettabile per IRT
        print("Dati adatti per analisi IRT")
        
        # Analisi fattoriale per identificare dimensioni latenti
        fa = FactorAnalyzer(n_factors=3, rotation='varimax', method='minres')
        fa.fit(df_likert)
        
        loadings = fa.loadings_
        communalities = fa.get_communalities()
        
        # Identifica item per dimensione
        loadings_df = pd.DataFrame(loadings, 
                                  columns=['Factor_1', 'Factor_2', 'Factor_3'],
                                  index=existing_likert)
        
        print(f"\nDimensioni identificate (loading > 0.4):")
        
        irt_factors = {}
        for factor in ['Factor_1', 'Factor_2', 'Factor_3']:
            strong_items = loadings_df[loadings_df[factor].abs() > 0.4][factor]
            if len(strong_items) > 0:
                irt_factors[factor] = strong_items.index.tolist()
                print(f"{factor}: {len(strong_items)} items")
                for item, loading in strong_items.items():
                    print(f"  {item}: {loading:.3f}")
        
        # Reliability analysis per ogni fattore
        print(f"\nReliability Analysis:")
        
        factor_reliabilities = {}
        for factor_name, items in irt_factors.items():
            if len(items) >= 3:  # Minimo per reliability
                factor_data = df_likert[items]
                
                # Cronbach's Alpha approssimato
                item_variances = factor_data.var(axis=0, ddof=1)
                total_variance = factor_data.sum(axis=1).var(ddof=1)
                k = len(items)
                
                if total_variance > 0:
                    alpha = (k / (k - 1)) * (1 - item_variances.sum() / total_variance)
                    factor_reliabilities[factor_name] = alpha
                    
                    reliability_level = "Eccellente" if alpha > 0.9 else "Buona" if alpha > 0.8 else "Accettabile" if alpha > 0.7 else "Questionabile"
                    print(f"{factor_name}: α = {alpha:.3f} ({reliability_level})")
                else:
                    factor_reliabilities[factor_name] = 0.0
                    print(f"{factor_name}: α non calcolabile (varianza zero)")
        
        # IRT Discrimination per item
        print(f"\nItem Discrimination Analysis:")
        
        # Calcola correlazioni item-total per ogni fattore
        item_discriminations = {}
        
        for factor_name, items in irt_factors.items():
            if len(items) >= 3:
                factor_data = df_likert[items]
                total_score = factor_data.sum(axis=1)
                
                discriminations = {}
                for item in items:
                    # Correlazione item con total (corrected item-total correlation)
                    item_total_corr = factor_data[item].corr(total_score - factor_data[item])
                    discriminations[item] = item_total_corr
                
                item_discriminations[factor_name] = discriminations
                
                print(f"{factor_name}:")
                for item, disc in discriminations.items():
                    disc_level = "Eccellente" if disc > 0.5 else "Buona" if disc > 0.3 else "Accettabile" if disc > 0.2 else "Debole"
                    print(f"  {item}: r = {disc:.3f} ({disc_level})")
    
    else:
        print(f"KMO troppo basso ({kmo_model:.3f}) - dati non adatti per IRT")
        irt_factors = {}
        factor_reliabilities = {}
        item_discriminations = {}
        
else:
    print("Troppo pochi casi completi per IRT analysis")
    irt_factors = {}
    factor_reliabilities = {}
    item_discriminations = {}

# =============================================================================
# STEP 4: MEASUREMENT INVARIANCE
# =============================================================================

print("\n=== STEP 4: Measurement Invariance Analysis ===")

# Test se il clustering è invariante across gruppi demografici
invariance_results = {}

# Gruppi da testare per invarianza
invariance_groups = {
    'Genere': df_processed['genere_raw'],
    'Occupazione_Studenti': df_processed['occup_studente'].map({0: 'Non_Studente', 1: 'Studente'}),
    'Eta_Generazione': df_processed['eta_raw'].apply(lambda x: 'Giovane' if x <= 30 else 'Adulto'),
    'Titolo_Studio': df_processed[['titolo_magistrale', 'titolo_postlaurea']].apply(
        lambda x: 'Laureato' if x['titolo_magistrale'] == 1 or x['titolo_postlaurea'] == 1 else 'Non_Laureato', axis=1)
}

print("Testing measurement invariance across gruppi demografici:")

for group_name, group_variable in invariance_groups.items():
    print(f"\n{group_name}:")
    
    group_counts = group_variable.value_counts()
    print(f"  Distribuzione: {dict(group_counts)}")
    
    # Filtra gruppi con almeno 30 casi ciascuno
    valid_groups = group_counts[group_counts >= 30].index.tolist()
    
    if len(valid_groups) >= 2:
        invariance_test_results = []
        
        for group_value in valid_groups:
            group_mask = (group_variable == group_value)
            
            # Clustering per gruppo
            X_group = X_clustering[group_mask]
            
            if len(X_group) >= 30:
                try:
                    kmeans_group = KMeans(n_clusters=3, random_state=42, n_init=10)
                    group_labels = kmeans_group.fit_predict(X_group)
                    
                    n_clusters_group = len(np.unique(group_labels))
                    
                    if n_clusters_group > 1:
                        group_silhouette = silhouette_score(X_group, group_labels)
                        
                        # ARI con clustering di riferimento (stesso gruppo)
                        reference_group = reference_labels[group_mask]
                        ari_group = adjusted_rand_score(reference_group, group_labels)
                        
                        invariance_test_results.append({
                            'Group_Value': group_value,
                            'N_Cases': len(X_group),
                            'Silhouette': group_silhouette,
                            'ARI_vs_Reference': ari_group,
                            'N_Clusters': n_clusters_group
                        })
                        
                        print(f"  {group_value}: n={len(X_group)}, Sil={group_silhouette:.3f}, ARI={ari_group:.3f}")
                    
                except Exception as e:
                    print(f"  {group_value}: Errore clustering")
        
        if len(invariance_test_results) >= 2:
            # Test invarianza: confronta stabilità tra gruppi
            aris = [r['ARI_vs_Reference'] for r in invariance_test_results]
            silhouettes = [r['Silhouette'] for r in invariance_test_results]
            
            ari_cv = np.std(aris) / np.mean(aris) if np.mean(aris) > 0 else np.inf
            sil_cv = np.std(silhouettes) / np.mean(silhouettes) if np.mean(silhouettes) > 0 else np.inf
            
            # Invarianza: bassa variabilità tra gruppi
            if ari_cv < 0.3 and sil_cv < 0.3:
                invariance_level = "Alta Invarianza"
            elif ari_cv < 0.5 and sil_cv < 0.5:
                invariance_level = "Media Invarianza"
            else:
                invariance_level = "Bassa Invarianza"
            
            invariance_results[group_name] = {
                'ARI_mean': np.mean(aris),
                'ARI_CV': ari_cv,
                'Silhouette_mean': np.mean(silhouettes),
                'Silhouette_CV': sil_cv,
                'Invariance_Level': invariance_level,
                'N_Groups_Tested': len(invariance_test_results)
            }
            
            print(f"  Invarianza: ARI_CV={ari_cv:.3f}, Sil_CV={sil_cv:.3f} → {invariance_level}")
        
        else:
            print(f"  Troppo pochi gruppi validi per test invarianza")
    
    else:
        print(f"  Gruppi insufficienti (< 30 casi) per test invarianza")

# =============================================================================
# STEP 5: RIEPILOGO TEST ROBUSTEZZA
# =============================================================================

print("\n=== RIEPILOGO TEST ROBUSTEZZA SURVEY DATA ===")

print(f"DATASET TESTATO: n={X_clustering.shape[0]}, p={X_clustering.shape[1]} variabili")
print(f"CLUSTERING RIFERIMENTO: K=3, distribuzione {np.bincount(reference_labels)}")

# 1. Sensitivity Analysis
print(f"\n1. SENSITIVITY ANALYSIS DEMOGRAFICA:")
if len(valid_results) > 0:
    avg_ari = valid_results['ARI_vs_Reference'].mean()
    ari_stability = "Alta" if avg_ari > 0.7 else "Media" if avg_ari > 0.5 else "Bassa"
    
    print(f"   Sottogruppi testati: {len(sensitivity_df)}")
    print(f"   Sottogruppi validi: {len(valid_results)}")
    print(f"   ARI medio: {avg_ari:.3f} ({ari_stability} stabilità)")
    
    # Robustezza per tipo demografico
    robust_subgroups = valid_results[valid_results['ARI_vs_Reference'] > 0.6]['Subgroup'].tolist()
    print(f"   Sottogruppi robusti (ARI>0.6): {robust_subgroups}")
else:
    print(f"   Nessun sottogruppo valido identificato")

# 2. IRT Analysis
print(f"\n2. ITEM RESPONSE THEORY:")
if irt_factors:
    print(f"   Fattori latenti identificati: {len(irt_factors)}")
    
    if factor_reliabilities:
        reliable_factors = sum(1 for alpha in factor_reliabilities.values() if alpha > 0.7)
        print(f"   Fattori affidabili (α>0.7): {reliable_factors}/{len(factor_reliabilities)}")
        
        avg_reliability = np.mean(list(factor_reliabilities.values()))
        rel_level = "Eccellente" if avg_reliability > 0.9 else "Buona" if avg_reliability > 0.8 else "Accettabile" if avg_reliability > 0.7 else "Questionabile"
        print(f"   Reliability media: α={avg_reliability:.3f} ({rel_level})")
    
    # Discriminazione item
    if item_discriminations:
        all_discriminations = []
        for factor_discs in item_discriminations.values():
            all_discriminations.extend(factor_discs.values())
        
        if all_discriminations:
            avg_discrimination = np.mean(all_discriminations)
            good_items = sum(1 for d in all_discriminations if d > 0.3)
            
            print(f"   Discriminazione media item: r={avg_discrimination:.3f}")
            print(f"   Item buoni (r>0.3): {good_items}/{len(all_discriminations)}")
else:
    print(f"   IRT non eseguibile (KMO insufficiente o dati inadeguati)")

# 3. Measurement Invariance
print(f"\n3. MEASUREMENT INVARIANCE:")
if invariance_results:
    high_invariance = sum(1 for r in invariance_results.values() if r['Invariance_Level'] == 'Alta Invarianza')
    
    print(f"   Dimensioni demografiche testate: {len(invariance_results)}")
    print(f"   Alta invarianza: {high_invariance}/{len(invariance_results)}")
    
    for dimension, results in invariance_results.items():
        print(f"   {dimension}: {results['Invariance_Level']} (ARI_CV={results['ARI_CV']:.3f})")
else:
    print(f"   Nessun test invarianza completato")

# Score finale robustezza
print(f"\n=== SCORE ROBUSTEZZA COMPLESSIVA ===")

# Calcola score composito
sensitivity_score = valid_results['ARI_vs_Reference'].mean() if len(valid_results) > 0 else 0.0
irt_score = np.mean(list(factor_reliabilities.values())) if factor_reliabilities else 0.5
invariance_score = np.mean([1.0 if r['Invariance_Level'] == 'Alta Invarianza' else 
                          0.7 if r['Invariance_Level'] == 'Media Invarianza' else 0.3 
                          for r in invariance_results.values()]) if invariance_results else 0.5

composite_robustness = (sensitivity_score * 0.4 + irt_score * 0.3 + invariance_score * 0.3)

if composite_robustness > 0.8:
    robustness_assessment = "ECCELLENTE ROBUSTEZZA"
elif composite_robustness > 0.7:
    robustness_assessment = "BUONA ROBUSTEZZA"
elif composite_robustness > 0.6:
    robustness_assessment = "ROBUSTEZZA ACCETTABILE"
else:
    robustness_assessment = "ROBUSTEZZA LIMITATA"

print(f"Score composito robustezza: {composite_robustness:.3f}")
print(f"Valutazione: {robustness_assessment}")

print(f"\nCONCLUSIONE:")
print(f"Il clustering K=3 mostra {robustness_assessment.lower()} sui test")
print(f"specialistici per survey data, confermando validità metodologica")
print(f"per applicazioni business nel dominio sostenibilità.")

print("\n=== MODULO TEST ROBUSTEZZA COMPLETATO ===")

# Export risultati per documentazione
sensitivity_df.to_csv('survey_robustness_sensitivity.csv', index=False)

robustness_summary = {
    'composite_score': composite_robustness,
    'assessment': robustness_assessment,
    'sensitivity_score': sensitivity_score,
    'irt_score': irt_score,
    'invariance_score': invariance_score,
    'n_subgroups_tested': len(sensitivity_df),
    'n_subgroups_valid': len(valid_results),
    'n_irt_factors': len(irt_factors),
    'n_invariance_tests': len(invariance_results)
}

import json
with open('survey_robustness_summary.json', 'w') as f:
    json.dump(robustness_summary, f, indent=2)

print("File salvati: survey_robustness_sensitivity.csv, survey_robustness_summary.json")
